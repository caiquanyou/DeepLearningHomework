# <center>手写数字识别实验报告</center>

## <center>摘要</center>

本次实验将采用深度学习中的卷积神经网络来训练MNIST数据集的手写数字识别模型。使用卷积神经网络建立合理的模型结构，在卷积层中设定一定数目一定大小的卷积核，通过训练数据使模型学习到能够反映出0-9十个不同手写数字特征的卷积核权值，最后给出预测数字图对应每种数字可能性的概率多少。实验中利用pytorch框架构建一个规范的卷积神经网络组织结构；对MNIST进行数据训练，最终在测试集上达到98.6%的准确率。

### 问题描述

手写数字识别是数字识别问题的其中一种，手写数字识别可以应用在各种人工签字场景下计算机对于人手写数字进行识别读取，简化人工成本。从Lecun等人成功把反向传播算法训练的卷积神经网络结合到读取识别手写数字开始，从0-9的简单手写数字识别已经成为计算机视觉领域入门的一个问题，也成为该领域的基础和基准任务，对不同算法的表现进行衡量。

### 解决方案

利用pytorch框架构建一个规范的卷积神经网络组织结构；在大型标准易用的成熟手写数字数据集MNIST进行训练数据和测试数据。

#### 损失函数设计

由于手写数字识别是一个多分类问题，在多分类问题中常使用交差熵作为损失函数，交叉熵定义如下：
$$
H_y(\hat y)=-\sum_i^n ylog\hat y
$$
其中y代表真实值，$\hat y$代表预测值，n代表需要区分的类别数，这里n取值为10，代表0-9十类数字。

#### 网络结构设计

采用规范的经典卷积神经网络结构，具体结构如下：

输入层：28\*28\*1的图片；

第一层卷积层1：设置了16个卷积核，卷积核大小为3\*3,填充层设置为2，步长为1，经过卷积层1 后输出为30\*30\*16；

第二层池化层1：使用最大池化进行下采样，池化的size选择(2,2)，得到15\*15\*16的图像特征；

第三层卷积层2：设置了32个卷积核，卷积核大小为4\*4,步长为1，经过卷积层2后输出为12\*12\*32；

第四层池化层2：使用最大池化进行下采样，池化的size选择(2,2)，得到6\*6\*32的图像特征；

第五层全连接层：输入为6\*6\*32个单元，输出为160个单元，每个单元与第4层中全部6\*6\*32个单元之间进行全连接；

第五层全连接层：输入为160个单元，输出为10个单元，每个单元与第4层中全部120个单元之间进行全连接。

输出层：10个结果：0-9的可能性。

### 实验分析

#### 数据集介绍

MNIST数据集是一个手写体数据集，数据集中每一个样本都是0-9中的某一个手写数字图片。该数据集由四部分组成，训练图片集，训练标签集，测试图片集和测试标签集。其中，训练集中有60000个样本，测试集中有10000个样本。每张照片均为28*28的灰度图像。为方便存储，官方已对图片集进行处理，将每一张图片变成了维度为(1,784)的向量。

#### 实验结果与分析

数据结果如下：

```
Train Times: 1 [51200/60000 (85%)]	Loss: 0.186183
Correct rate is : 94.450000 %,Loss is 	0.116982
Train Times: 2 [51200/60000 (85%)]	Loss: 0.117892
Correct rate is : 97.200000 %,Loss is 	0.141368
Train Times: 3 [51200/60000 (85%)]	Loss: 0.214576
Correct rate is : 97.650000 %,Loss is 	0.042133
Train Times: 4 [51200/60000 (85%)]	Loss: 0.140856
Correct rate is : 97.940000 %,Loss is 	0.015425
Train Times: 5 [51200/60000 (85%)]	Loss: 0.053606
Correct rate is : 98.160000 %,Loss is 	0.028374
Train Times: 6 [51200/60000 (85%)]	Loss: 0.068550
Correct rate is : 98.120000 %,Loss is 	0.034219
Train Times: 7 [51200/60000 (85%)]	Loss: 0.029233
Correct rate is : 98.310000 %,Loss is 	0.002387
Train Times: 8 [51200/60000 (85%)]	Loss: 0.010530
Correct rate is : 98.520000 %,Loss is 	0.010708
Train Times: 9 [51200/60000 (85%)]	Loss: 0.028506
Correct rate is : 98.450000 %,Loss is 	0.045098
Train Times: 10 [51200/60000 (85%)]	Loss: 0.021155
Correct rate is : 98.410000 %,Loss is 	0.000270
Train Times: 11 [51200/60000 (85%)]	Loss: 0.038200
Correct rate is : 98.580000 %,Loss is 	0.011471
Train Times: 12 [51200/60000 (85%)]	Loss: 0.026102
Correct rate is : 98.600000 %,Loss is 	0.024337
```

![](C:\Users\alienware\Desktop\Figure_1.png)

可以看出在第5次迭代后，准确率已经达到了98%以上，后续迭代中准确率的提升不明显，且偶尔会出现准确率降低。

### 总结

深度学习领域中使用MNIST数据集实现卷积神经网络的训练已经成为了一个入门教程。这次实验中从零开始学习如何利用pytorch框架搭建卷积神经网络解决问题，从实际项目学习巩固课堂上关于卷积神经网络的知识，在完成过程中所遇到的问题大部分通过搜索谷歌等网上的资源可以得到很好的解决。实验中模型在测试集上表现达到98.6%的准确度，但是在训练中准确率会来回跳，这说明整体模型还有改进和提升的空间。

